{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 11: Classifications\n",
    "Cheng Ching Hung\n",
    "\n",
    "Fan Ting Hay\n",
    "## Due by 23:55 on Thursday 7/30/2020 \n",
    "Welcome to Lab 11! This is our last lab so you made it!\n",
    "\n",
    "We will try to further develop our understanind of classification and use it on music classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell, but please don't change it.\n",
    "\n",
    "# These lines import the Numpy and Datascience modules.\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "from lab10_knn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What is classification?\n",
    "### Classification\n",
    "Classification is a special kind of prediction.  We see some information about an entity and we want to predict other information about that entity.  The predicted information is *categorical*, like \"Yes\" or \"No\", not *numeric*, like 5 or 5.1.\n",
    "\n",
    "Unfortunately, practitioners use different terms for these things.  Entities might also be called *examples*.  The information we see about each entity is called its *attributes* or *features*.  The thing we’re trying to predict about each entity is called its *outcome*, *class*, *label*, or *true value*.  Our prediction itself is called a *predicted outcome*, *predicted class*, *predicted label*, or *predicted value*.\n",
    "\n",
    "In Project 2, the entities are songs, the features are data on the song’s lyrics (the words in the song), and the class will be the song’s genre (country or hip-hop).  Below is a table called `lyrics` with a small example of song data.  Each row represents a song.  The first column is the true label of each song.  The other columns record how frequently the words \"the\", \"a\", \"style\", \"girl\", \"boy\", \"yo\", and \"truck\" appeared in the song.  In the actual project, the data are much richer than this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Genre</th> <th>the</th> <th>a</th> <th>style</th> <th>girl</th> <th>boy</th> <th>yo</th> <th>truck</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Hip-hop</td> <td>0.767442 </td> <td>0.162791 </td> <td>0.0232558</td> <td>0        </td> <td>0        </td> <td>0.0465116</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Country</td> <td>0.529412 </td> <td>0.294118 </td> <td>0        </td> <td>0.176471 </td> <td>0        </td> <td>0        </td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Country</td> <td>0.5      </td> <td>0.5      </td> <td>0        </td> <td>0        </td> <td>0        </td> <td>0        </td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Country</td> <td>0.5      </td> <td>0.375    </td> <td>0        </td> <td>0.125    </td> <td>0        </td> <td>0        </td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Hip-hop</td> <td>0.0588235</td> <td>0.882353 </td> <td>0        </td> <td>0.0588235</td> <td>0        </td> <td>0        </td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Hip-hop</td> <td>0.583333 </td> <td>0.416667 </td> <td>0        </td> <td>0        </td> <td>0        </td> <td>0        </td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Hip-hop</td> <td>0.617647 </td> <td>0.264706 </td> <td>0.0294118</td> <td>0        </td> <td>0        </td> <td>0.0882353</td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Hip-hop</td> <td>0.516129 </td> <td>0.354839 </td> <td>0        </td> <td>0.0967742</td> <td>0.0322581</td> <td>0        </td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Country</td> <td>0.333333 </td> <td>0.333333 </td> <td>0        </td> <td>0.333333 </td> <td>0        </td> <td>0        </td> <td>0    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Country</td> <td>0.692308 </td> <td>0.0769231</td> <td>0        </td> <td>0.230769 </td> <td>0        </td> <td>0        </td> <td>0    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (90 rows omitted)</p>"
      ],
      "text/plain": [
       "Genre   | the       | a         | style     | girl      | boy       | yo        | truck\n",
       "Hip-hop | 0.767442  | 0.162791  | 0.0232558 | 0         | 0         | 0.0465116 | 0\n",
       "Country | 0.529412  | 0.294118  | 0         | 0.176471  | 0         | 0         | 0\n",
       "Country | 0.5       | 0.5       | 0         | 0         | 0         | 0         | 0\n",
       "Country | 0.5       | 0.375     | 0         | 0.125     | 0         | 0         | 0\n",
       "Hip-hop | 0.0588235 | 0.882353  | 0         | 0.0588235 | 0         | 0         | 0\n",
       "Hip-hop | 0.583333  | 0.416667  | 0         | 0         | 0         | 0         | 0\n",
       "Hip-hop | 0.617647  | 0.264706  | 0.0294118 | 0         | 0         | 0.0882353 | 0\n",
       "Hip-hop | 0.516129  | 0.354839  | 0         | 0.0967742 | 0.0322581 | 0         | 0\n",
       "Country | 0.333333  | 0.333333  | 0         | 0.333333  | 0         | 0         | 0\n",
       "Country | 0.692308  | 0.0769231 | 0         | 0.230769  | 0         | 0         | 0\n",
       "... (90 rows omitted)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics = Table.read_table(\"lyrics_example.csv\")\n",
    "lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers\n",
    "A *classifier* is a piece of software that takes in information about something and produces a predicted value.\n",
    "\n",
    "In the project your classifier will be a Python function that takes data on a song’s lyrics as an argument and returns a string like “Hip-hop” or “Country”.\n",
    "\n",
    "<img src=\"1_classifier.jpg\">\n",
    "\n",
    "For concreteness, here's an example of a simple and very inaccurate song-genre classifier.  It's fully documented so you can figure out how to call it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def really_bad_classifier(song_features):\n",
    "    \"\"\"\n",
    "    Produces a predicted label for a song with the given features.\n",
    "    \n",
    "    song_features should be a row of a table like lyrics, except that\n",
    "    it shouldn't include the column with the true label.  For example,\n",
    "    you could call this function like this to classify the first\n",
    "    example in the lyrics table:\n",
    "    \n",
    "      really_bad_classifier(lyrics.drop(\"Genre\").row(0))\n",
    "    \n",
    "    Returns a string that's the predicted label for the given song.\n",
    "    In this case, labels are the string \"Country\" or \"Hip-hop\".\n",
    "    \n",
    "    This function actually doesn't do anything intelligent, as you\n",
    "    can see below.\n",
    "    \"\"\"\n",
    "    # We just check whether the thousandths digit of the first\n",
    "    # feature is odd or even.\n",
    "    if (1000 * song_features.item(0)) % 2 == 0:\n",
    "        return \"Country\"\n",
    "    else:\n",
    "        return \"Hip-hop\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.** Compute `really_bad_classifier`'s predictions for the songs in `lyrics` with indices 90 through 94 (inclusive).\n",
    "\n",
    "*Hint:* Two Table methods will be useful:\n",
    "* If `t` is a table, then `t.take(range(3, 6))` is a smaller version of `t` with only rows 3, 4, and 5.\n",
    "* `t.apply(f)` calls the function `f` on each *row* in the table `t`, producing an array of the values returned by `f` for each row.  It's the same as saying `np.array([f(t.row(0)), f(t.row(1)), f(t.row(2), ...])`.  `t.row(i)` is basically a list of the things in row `i` of table `t`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hip-hop', 'Hip-hop', 'Country', 'Hip-hop', 'Country'], dtype='<U7')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_predictions =  lyrics.take(range(90, 95)).drop(\"Genre\").apply(really_bad_classifier)\n",
    "bad_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2.** Compute the proportion of right answers `really_bad_classifier` got on that 5-song dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.count_nonzero(bad_predictions==lyrics.take(range(90, 95)).column(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportion_right_answers =  np.count_nonzero(bad_predictions==lyrics.take(range(90, 95)).column(0))/5\n",
    "proportion_right_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a classifier\n",
    "The classification methods we’re looking at in this class require examples of labeled data.  That is, we need some data where we know both the features and the true label.  We use that data to *train* a classifier to make predictions that match many of the true labels for the training data.  Hopefully it will make good predictions for other data it hasn't seen, too.\n",
    "\n",
    "<img src=\"1_training.jpg\">\n",
    "\n",
    "The box that takes training data and makes a classifier is *itself* a Python function, which we might call a training function.  Since a classifier is a function, a training function that produces a classifier is a *higher-order function* -- a function that returns another function.\n",
    "\n",
    "`make_classifier` in the next cell is an example of a training function.  To avoid spoilers, it makes classifiers that aren't quite the same as the k-Nearest Neighbors classifiers you'll work with in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_classifier(training_data):\n",
    "    \"\"\"\n",
    "    Takes a table of labeled examples and returns a classifier function\n",
    "    trained on that data.\n",
    "    \n",
    "    The resulting classifier function behaves like really_bad_classifier\n",
    "    in exercise 1.1, in the sense that it takes the same arguments and\n",
    "    produces the same kind of output.  It produces slightly more sensible\n",
    "    results than really_bad_classifier.\n",
    "    \n",
    "    training_data should be a table of data like the lyrics table.  Each\n",
    "    row should represent one song.  Its first column should be the true\n",
    "    genre of each song.  All other columns should be features.\n",
    "    \"\"\"\n",
    "    averages_by_genre = training_data.group(\"Genre\", np.mean)\n",
    "    country_averages = np.array(averages_by_genre.where(\"Genre\", \"Country\").drop(\"Genre\").row(0))\n",
    "    hiphop_averages = np.array(averages_by_genre.where(\"Genre\", \"Hip-hop\").drop(\"Genre\").row(0))\n",
    "    \n",
    "    def classifier(features):\n",
    "        features_array = np.array(features)\n",
    "        if sum(abs(features_array - country_averages)) <= sum(abs(features_array - hiphop_averages)):\n",
    "            return \"Country\"\n",
    "        else:\n",
    "            return \"Hip-hop\"\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3.** Read the documentation of the function `make_classifier`.  Use it to make a classifier function called `my_classifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classifier = make_classifier(lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4.** Use `my_classifier` to make a prediction for the song with index 90 in `lyrics`.\n",
    "\n",
    "*Hint:* If you get an error like \"`TypeError: ufunc 'subtract' did not contain...`\", make sure you're calling `my_classifier` with only the *features* in the `lyrics` table.  It will be confused if your row includes the actual genre of the song.\n",
    "\n",
    "*Hint 2:* If you get an error like \"`ValueError: invalid __array_struct__`\", make sure you're calling `my_classifier` with a *row* of the `lyrics` table (using `.row(...)`), not a table containing only one row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hip-hop'], dtype='<U7')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction =lyrics.take(90).drop(\"Genre\").apply(my_classifier)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Goals of classification\n",
    "### What is our goal when we classify?\n",
    "\n",
    "We have some *population* of songs in mind, and we're eventually going to use our classifier to make predictions about songs from that population.  That means we care about the proportion of correct predictions our classifier makes *for that entire population*.  An ideal song classifier would work well on all the hip-hop and country songs that have ever been written or will ever be written.  We might have to settle for something that works well on the songs we have available to us.\n",
    "\n",
    "<img src=\"2_population_accuracy.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we try to make a classifier that meets that goal?\n",
    "We usually don’t have access to the outcomes of everything in the population.  If we did, we wouldn't be interested in predicting them!\n",
    "\n",
    "The fact that we don't know about the whole population raises difficulties both in *training a good classifier* and in *measuring how well our classifier works*.  First let's talk about training.\n",
    "\n",
    "A typical case is that we have data from a sample of the population.  It might not be a simple random sample.  For example, we can't know about songs that will be written in the future, even if we want our classifier to work well on them.  In the project, we have a dataset of about 1800 songs whose lyrics and genres were recorded in an online database.\n",
    "\n",
    "To train a classifier, we use our available sample -- our *training set* -- to make a classifier that we hope works well on the population.  To classify a song whose label we don't know, the idea is generally to find songs in the training set that are similar to the song, and to use those songs' labels to predict the song's label.\n",
    "\n",
    "<img src=\"2_sample_training.jpg\">\n",
    "\n",
    "Here's a lightning review of what a k-Nearest-Neighbors classifier does.  To classify a song, it finds `k` songs in the training set whose lyrics are most similar to the song (as measured by Euclidean distance between the word frequencies).  It predicts that the song's genre is the genre most common among those similar songs.  For details about k-Nearest-Neighbors classification, you might want to review the [lecture webcast](https://data-8.appspot.com/sp16/unit?unit=5&lesson=24) or the [textbook chapter](http://www.inferentialthinking.com/chapter4/classification.html) on classification.\n",
    "\n",
    "Below is a picture of a small made-up training set with only 2 features (which is the most we can easily visualize).  Each point represents a song.  On the horizontal axis is the frequency of the word \"style\", and on the vertical axis is the frequency of the word \"truck\".  Blue triangles are hip-hop songs and red circles are country songs.  We've placed the axes a bit below 0% for visual clarity.\n",
    "\n",
    "<img src=\"2_training_graph.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1.** Why are so many of the points at 0% for one or both features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It means that the frequency is 0%; that is, the word \"truck\" or \"style\" does not appear in the lyric, and the lyrics are not simmilar to the song."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.** How would a 3-Nearest Neighbor classifier trained on this data classify a song located at the center of the big star?\n",
    "\n",
    "<img src=\"2_2_song.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to either the string \"Country\" or the string \"Hip-hop\",\n",
    "# depending on how you think a 3-NN classifier will classify the\n",
    "# star.\n",
    "q22_classification = \"Country\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.** How would a 1-Nearest Neighbor classifier trained on the same data classify that song?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to either the string \"Country\" or the string \"Hip-hop\",\n",
    "# depending on how you think a 1-NN classifier will classify the\n",
    "# star.\n",
    "q23_classification = \"Country\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4.** How would a 3-Nearest Neighbor classifier classify a song located at the center of the big star?\n",
    "\n",
    "<img src=\"2_4_song.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to either the string \"Country\" or the string \"Hip-hop\",\n",
    "# depending on how you think a 3-NN classifier will classify the\n",
    "# star.\n",
    "q24_classification = \"Country\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5.** How would a 1-Nearest Neighbor classifier classify that song?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to either the string \"Country\" or the string \"Hip-hop\",\n",
    "# depending on how you think a 1-NN classifier will classify the\n",
    "# star.\n",
    "q25_classification = \"Hip-hop\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6.** Describe two regions of \"style\"-\"truck\" space (that is, two regions of the graph) where a 1-Nearest Neighbor classifier makes decisions that seem wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the figure, it shows that the 'country' songs are more likely to have 0% frequency of \"truck\" while the 'hip-hop' song are more likely to have 0% frequency of \"style\". The star has 0% frequency of \"truck\", but its nearest neighbour is 'hip-hop' music. The 1-Nearest Neighbour classifier is the not the same as the 3-Nearest Neighbour classifier. Hence, it is likely that the decisions made by 1-Nearest Neighbor classifier is wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we measure whether we’ve met our goals?\n",
    "k-Nearest Neighbors sounds reasonable, but as you saw above, it's not always going to work well.  Depending on the application, the consequences of bad classication could range from losing a company money to endangering patients' lives.  So before we use a classifier, it's important to verify that it works well enough for the application.\n",
    "\n",
    "Ideally, we'd make a prediction for everyone in the population and check how many we get right, in the same way you checked a classifier's accuracy for a few songs in question 1.2.\n",
    "\n",
    "<img src=\"2_population_accuracy_redux.jpg\">\n",
    "\n",
    "But again, we don’t have access to the outcomes of everyone in the population.\n",
    "This is a problem we’ve seen and solved before.  When pollsters want to find out what proportion of people in a population will vote for a candidate, they take a random sample and estimate the population proportion by the sample proportion.\n",
    "\n",
    "<img src=\"2_polling_example.jpg\">\n",
    "\n",
    "Similarly, we can compute the accuracy of our classifier on a sample that we do have access to.\n",
    "\n",
    "<img src=\"2_sample_accuracy.jpg\">\n",
    "\n",
    "In practice we usually have access to just 1 dataset, so we use part of it to train and the rest to test, simulating two separate samples from the population.  Often the first step in a data analysis is to split all the available data into a training set and a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we use separate data for training and test?  Because a classifier will often work better on its training data than on the rest of the population.  If we train and test on the same data, the picture looks like this:\n",
    "\n",
    "<img src=\"2_test_on_training.jpg\">\n",
    "\n",
    "...but if we use separate data, then it looks like this:\n",
    "\n",
    "<img src=\"2_test_on_test.jpg\">\n",
    "\n",
    "**Question 2.7.** Explain this phenomenon in your own words.  Concretely, say that we have one random sample from the population and we use that whole sample to train **and** the same sample to test.  Why isn’t that like testing on a separate random sample from the population?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the train and test sample is able to minimize the effects of the discrepancies of data, and the characteristics of the model will be estimate more accurate. By using the test sample, we are able to determine whether the model is underfitting or overfitting the data. Hence, it can reduce the biasedness of the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example\n",
    "Suppose we train a 1-Nearest Neighbor classifier on the training data in this picture:\n",
    "\n",
    "<img src=\"2_training_graph.jpg\">\n",
    "\n",
    "We'll use the classifier trained on this data for questions 2.8 through 2.9.\n",
    "\n",
    "**Question 2.8.** What is the accuracy of the classifier on *the same training set*?  That is, what proportion of songs in the training set are correctly classified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "q28_accuracy = 17/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose our population actually looks like this:\n",
    "\n",
    "<img src=\"2_population_graph.jpg\">\n",
    "\n",
    "**Question 2.9.** Is the true accuracy (the accuracy on the whole population) of the classifier roughly the same as its accuracy on the training set, which we computed above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, it is roughly the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we take a new sample from the population (disjoint from the training set) and use that as our test set.  The training set (the same one we've been using for this whole section) is overlaid for convenience.\n",
    "\n",
    "<img src=\"2_test_graph.jpg\">\n",
    "\n",
    "**Question 2.10.** What is the exact accuracy of the 1-Nearest Neighbor classifier on this test set?  You'll have to manually examine each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "q210_accuracy = 6/10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
